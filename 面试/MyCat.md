# MyCat

## 一、分库分表分类

### 垂直切分

#### :one:数据库的垂直切分

> ​		根据业务耦合性，关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与"微服务治理"的做法相似，每个微服务使用单独的一个数据库。这种拆分要注意需要杜绝跨库关联查询。
>
> 

#### :two:表的垂直切分

> 某个表字段较多，可以新建一张扩展表，将不经常用或字段长度较大的字段拆分出去到扩展表中。



### 水平切分

```
就是同一个表中的数据分散到多个相同表中，如果这些表在同一个库中就是库内分表，如果在不同库中就是分库分表
```



#### :one:库内分表

> ​		库内分表只解决了单一表数据量过大的问题，但没有将表分布到不同机器的库上，因此对于减轻MySQL数据库的压力来说，帮助不是很大，大家还是竞争同一个物理机的CPU、内存、网络IO，最好通过分库分表来解决。

#### :two:分库分表

> - 不存在单库数据量过大、高并发的性能瓶颈，提升系统稳定性和负载能力
> - 应用端改造较小，不需要拆分业务模块

#### 水平切分的存在的一些问题？

```
跨分片的事务一致性难以保证
跨库的join关联查询性能较差
数据多次扩展难度和维护量极大
```

**水平切分后同一张表会出现在多个数据库/表中，每个库/表的内容不同。**

#### 水平切分分片规则

##### 根据数值范围

```
按照时间区间或ID区间来切分。例如：按日期将不同月甚至是日的数据分散到不同的库中；
将userId为1~9999的记录分到第一个库，10000~20000的分到第二个库，以此类推。
```

优点:

```
单表大小可控
天然便于水平扩展，后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移
使用分片字段进行范围查找时，连续分片可快速定位分片进行快速查询，有效避免跨分片查询的问题。
```

缺点：

```
热点数据成为性能瓶颈。累的累死，闲的闲死。
```

##### 根据数值取模

```
一般采用hash取模mod的切分方式，例如：将 Customer 表根据 cusno 字段切分到4个库中，余数为0的放到第一个库，余数为1的放到第二个库，以此类推。这样同一个用户的数据会分散到同一个库中，如果查询条件带有cusno字段，则可明确定位到相应库去查询。
```

优点:

```
数据分片相对比较均匀，不容易出现热点和并发访问的瓶颈
```

缺点：

```
容易面临跨分片查询的复杂问题。
```

##### 分片枚举

```
比如 表中有个省份字段  使用枚举分片 就可以把 安徽 浙江 江苏 存在三个节点中
```



##### 一致性 hash    

```
后期分片集群扩容时，需要迁移旧的数据.（使用一致性hash算法能较好的避免这个问题）  解决分布式扩容问题
```

```xml
<tableRule name="sharding-by-murmur">
    <rule>
        <columns>user_id</columns>
        <algorithm>murmur</algorithm>
    </rule>
</tableRule>
<function name="murmur" class="io.mycat.route.function.PartitionByMurmurHash">
    <!-- 默认是 0 -->
    <property name="seed">0</property>
    <!-- 要分片的数据库节点数量，必须指定，否则没法分片 -->
    <property name="count">2</property>
    <!-- 一个实际的数据库节点被映射为这么多虚拟 节点，默认是 160 倍，也就是虚拟节点数是物理节点数的 160 倍 -->
    <property name="virtualBucketTimes">160</property>
    <!-- 节点的权重，没有指定权重的节点默认是 1。以 properties 文件的格式填写，以从 0 开始到 count-1 的整数值也就是节点索引为 key，以节点权重值为值。所有权重值必须是正整数，否则以 1 代替 -->
    <property name="weightMapFile">weightMapFile</property>
    <!-- 用于测试时观察各物理节点与虚拟节点的分布情况，如果指定了这个属性，会把虚拟节点的 murmur hash 值与物理节 点的映射按行输出到这个文件，没有默认值，如果不指定，就不会输出任何东西 -->
    <property name="bucketMapPath">/etc/mycat/bucketMapPath</property>
</function>
```



[大佬讲解一致性hash,通俗易懂](https://www.zsythink.net/archives/1182)

## 三、分库分表带来的问题



> 分布式事务   <font color='red'>一般可使用"XA协议"和"两阶段提交"处理</font>

当更新内容同时分布在不同库中，不可避免会带来跨库事务问题。跨分片事务也是分布式事务，没有简单的方案，一般可使用"XA协议"和"两阶段提交"处理。

> 最终一致性



> **跨节点关联查询 join 问题**



## 读写分离



### 如何实现 MySQL 的读写分离？

```
其实很简单，就是基于主从复制架构，简单来说，就搞一个主库，挂多个从库，然后我们就单单只是写主库，然后主库会自动把数据给同步到从库上去。
```



### MySQL 主从复制原理的是啥？

```
主库将变更写入 binlog 日志，然后从库连接到主库之后，从库有一个 IO 线程，将主库的 binlog 日志拷贝到自己本地，写入一个 relay 中继日志中。接着从库中有一个 SQL 线程会从中继日志读取 binlog，然后执行 binlog 日志中的内容，也就是在自己本地再次执行一遍 SQL，这样就可以保证自己跟主库的数据是一样的。
```



### MySQL 主从同步延时问题（精华）

```
以前线上确实处理过因为主从同步延时问题而导致的线上的 bug，属于小型的生产事故。

是这个么场景。有个同学是这样写代码逻辑的。先插入一条数据，再把它查出来，然后更新这条数据。在生产环境高峰期，写并发达到了 2000/s，这个时候，主从复制延时大概是在小几十毫秒。线上会发现，每天总有那么一些数据，我们期望更新一些重要的数据状态，但在高峰期时候却没更新。用户跟客服反馈，而客服就会反馈给我们。

我们通过 MySQL 命令：
show status 查看 Seconds_Behind_Master，可以看到从库复制主库的数据落后了几 ms。
一般来说，如果主从延迟较为严重，有以下解决方案：

- 分库，将一个主库拆分为多个主库，每个主库的写并发就减少了几倍，此时主从延迟可以忽略不计。
- 打开 MySQL 支持的并行复制，多个库并行复制。如果说某个库的写入并发就是特别高，单库写并发达到了 2000/s，并行复制还是没意义。
- 重写代码，写代码的同学，要慎重，插入数据时立马查询可能查不到。
```



### JAVA代码中怎么实现？

```
简单讲解思路
   spring 是支持多数据源的，多个 datasource 放在一个 HashMap  TargetDataSource中，通过dertermineCurrentLookupKey获取 key 来觉定要使用哪个数据源。因此我们的目标就很明确了，建立多个 datasource 放到 TargetDataSource 中，同时重写 dertermineCurrentLookupKey 方法来决定使用哪个 key。
   
   如何选择数据源   
   		切面   在细节点的地方   可以通过自定义注解或者方法名来区分使用哪个数据源   
   		通过AOP  使用环绕通知 ThreadLoal清除之前放的数据源对象  一方面为了避免内存泄漏，更重要的是避免对后续在本线程上执行的操作产生影响  
   		记得 判断出来 是使用哪个数据源之后 可以用ThreadLoal创建一个对象，创建一个存储上当前数据源 
   重写 determineCurrentLookupKey 方法
   spring 在开始进行数据库操作时会通过这个方法来决定使用哪个数据库，因此我们在这里调用上面 DbContextHolder 类的getDbType()方法获取当前操作类别,同时可进行读库的负载均衡。
   	事务一一般是注解在 Service 层的，因此在开始这个 service 方法调用时要确定数据源，有什么通用方法能够在开始执行一个方法前做操作呢
```

